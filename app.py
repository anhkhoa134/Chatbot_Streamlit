import streamlit as st
import requests

# Thi·∫øt l·∫≠p URL API LM Studio
API_URL = "http://100.65.5.56:1234/v1/chat/completions"
HEADERS = {
    "Content-Type": "application/json"
}
MODEL_NAME = "gemma-2-9b-it"

# H√†m g·ª≠i message t·ªõi LM Studio
def chat_with_bot(messages):
    data = {
        "model": MODEL_NAME,
        "messages": messages,
        "temperature": 0.7,
        "max_tokens": 500
    }
    response = requests.post(API_URL, headers=HEADERS, json=data)
    if response.status_code == 200:
        return response.json()['choices'][0]['message']['content']
    else:
        return "C√≥ l·ªói x·∫£y ra khi k·∫øt n·ªëi ƒë·∫øn LM Studio."

# Giao di·ªán Streamlit
st.title("ü¶ô Chatbot LM Studio (Gemma-2-9B-IT)")

if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "system", "content": "B·∫°n ƒëang tr√≤ chuy·ªán v·ªõi chatbot LM Studio!"}
    ]

# Hi·ªÉn th·ªã c√°c tin nh·∫Øn tr∆∞·ªõc ƒë√≥
for msg in st.session_state.messages:
    if msg["role"] != "system":
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

# √î nh·∫≠p li·ªáu
user_input = st.chat_input("Nh·∫≠p tin nh·∫Øn...")

if user_input:
    # Th√™m message ng∆∞·ªùi d√πng v√†o session
    st.session_state.messages.append({"role": "user", "content": user_input})

    # Hi·ªÉn th·ªã tin nh·∫Øn ng∆∞·ªùi d√πng
    with st.chat_message("user"):
        st.markdown(user_input)

    # G·ª≠i v√† hi·ªÉn th·ªã ph·∫£n h·ªìi t·ª´ chatbot
    with st.chat_message("assistant"):
        response = chat_with_bot(st.session_state.messages)
        st.markdown(response)

    # Th√™m tin nh·∫Øn chatbot v√†o session
    st.session_state.messages.append({"role": "assistant", "content": response})
